[project]
name = "paperrag"
version = "0.3.1"
description = "Local RAG for academic PDFs"
authors = [{name = "PaperRAG Team"}]
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "docling",
    "sentence-transformers",
    "faiss-cpu",
    "torch",
    "numpy",
    "pydantic>=2.5,<3.0",
    "typer>=0.9",
    "rich>=13.0",
    "tqdm>=4.66",
    "python-dotenv>=1.0,<2.0",
    "psutil>=5.9",
    "pymupdf>=1.23",  # For PDF text detection
    "prompt-toolkit>=3.0",  # For REPL command history
    "openai>=1.0,<2.0",
]

[project.optional-dependencies]
gpu = [
    "torch",  # reinstalled from default PyPI index (CUDA-bundled)
]
llm = [
    "transformers>=4.38",
    "accelerate>=0.27",
]
test = [
    "pytest>=8.0",
]
docs = [
    "sphinx>=7.0",
    "myst-parser>=2.0",
    "furo",
]

[project.scripts]
paperrag = "paperrag.cli:app"

[build-system]
requires = ["setuptools>=68.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["paperrag"]

# CPU-only torch is the default (avoids ~2.5GB CUDA download).
# Install with GPU/CUDA support: uv pip install -e ".[gpu]"
#
# How it works:
#   - Default (no extras): torch pulled from pytorch-cpu index (CPU-only, ~200MB)
#   - With [gpu] extra: torch pulled from PyPI (CUDA-bundled, ~2.5GB)
[tool.uv.sources]
torch = [
    { index = "pytorch-cpu", marker = "extra != 'gpu'" },
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true
